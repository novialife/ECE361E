[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 28, 28]          320
├─MaxPool2d: 1-2                         [-1, 32, 14, 14]          --
├─Conv2d: 1-3                            [-1, 64, 14, 14]          18,496
├─MaxPool2d: 1-4                         [-1, 64, 7, 7]            --
├─Conv2d: 1-5                            [-1, 128, 7, 7]           73,856
├─MaxPool2d: 1-6                         [-1, 128, 3, 3]           --
├─Linear: 1-7                            [-1, 10]                  11,530
==========================================================================================
Total params: 104,202
Trainable params: 104,202
Non-trainable params: 0
Total mult-adds (M): 7.46
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.34
Params size (MB): 0.40
Estimated Total Size (MB): 0.74
==========================================================================================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [-1, 32, 28, 28]          320
├─MaxPool2d: 1-2                         [-1, 32, 14, 14]          --
├─Conv2d: 1-3                            [-1, 64, 14, 14]          18,496
├─MaxPool2d: 1-4                         [-1, 64, 7, 7]            --
├─Conv2d: 1-5                            [-1, 128, 7, 7]           73,856
├─MaxPool2d: 1-6                         [-1, 128, 3, 3]           --
├─Linear: 1-7                            [-1, 10]                  11,530
==========================================================================================
Total params: 104,202
Trainable params: 104,202
Non-trainable params: 0
Total mult-adds (M): 7.46
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.34
Params size (MB): 0.40
Estimated Total Size (MB): 0.74
==========================================================================================
Epoch: [1/25], Step: [100/468], Loss: 0.8546 Acc: 73.82%
Epoch: [1/25], Step: [200/468], Loss: 0.5005 Acc: 84.58%
Epoch: [1/25], Step: [300/468], Loss: 0.3677 Acc: 88.65%
Epoch: [1/25], Step: [400/468], Loss: 0.2964 Acc: 90.86%
Test accuracy: 98.09 % Test loss: 0.0587
Epoch: [2/25], Step: [100/468], Loss: 0.0721 Acc: 97.61%
Epoch: [2/25], Step: [200/468], Loss: 0.0671 Acc: 97.89%
Epoch: [2/25], Step: [300/468], Loss: 0.0629 Acc: 98.05%
Epoch: [2/25], Step: [400/468], Loss: 0.0603 Acc: 98.12%
Test accuracy: 98.14 % Test loss: 0.0574
Epoch: [3/25], Step: [100/468], Loss: 0.0433 Acc: 98.62%
Epoch: [3/25], Step: [200/468], Loss: 0.0435 Acc: 98.63%
Epoch: [3/25], Step: [300/468], Loss: 0.0416 Acc: 98.70%
Epoch: [3/25], Step: [400/468], Loss: 0.0415 Acc: 98.70%
Test accuracy: 99.02 % Test loss: 0.0298
Epoch: [4/25], Step: [100/468], Loss: 0.0293 Acc: 99.11%
Epoch: [4/25], Step: [200/468], Loss: 0.0320 Acc: 99.00%
Epoch: [4/25], Step: [300/468], Loss: 0.0325 Acc: 98.97%
Epoch: [4/25], Step: [400/468], Loss: 0.0332 Acc: 98.97%
Test accuracy: 98.97 % Test loss: 0.0322
Epoch: [5/25], Step: [100/468], Loss: 0.0263 Acc: 99.18%
Epoch: [5/25], Step: [200/468], Loss: 0.0273 Acc: 99.16%
Epoch: [5/25], Step: [300/468], Loss: 0.0269 Acc: 99.16%
Epoch: [5/25], Step: [400/468], Loss: 0.0267 Acc: 99.17%
Test accuracy: 99.03 % Test loss: 0.0297
Epoch: [6/25], Step: [100/468], Loss: 0.0188 Acc: 99.38%
Epoch: [6/25], Step: [200/468], Loss: 0.0201 Acc: 99.35%
Epoch: [6/25], Step: [300/468], Loss: 0.0229 Acc: 99.30%
Epoch: [6/25], Step: [400/468], Loss: 0.0241 Acc: 99.28%
Test accuracy: 99.17 % Test loss: 0.0264
Epoch: [7/25], Step: [100/468], Loss: 0.0167 Acc: 99.51%
Epoch: [7/25], Step: [200/468], Loss: 0.0171 Acc: 99.46%
Epoch: [7/25], Step: [300/468], Loss: 0.0180 Acc: 99.41%
Epoch: [7/25], Step: [400/468], Loss: 0.0178 Acc: 99.45%
Test accuracy: 99.09 % Test loss: 0.0262
Epoch: [8/25], Step: [100/468], Loss: 0.0124 Acc: 99.65%
Epoch: [8/25], Step: [200/468], Loss: 0.0134 Acc: 99.63%
Epoch: [8/25], Step: [300/468], Loss: 0.0143 Acc: 99.57%
Epoch: [8/25], Step: [400/468], Loss: 0.0153 Acc: 99.53%
Test accuracy: 99.15 % Test loss: 0.0282
Epoch: [9/25], Step: [100/468], Loss: 0.0103 Acc: 99.72%
Epoch: [9/25], Step: [200/468], Loss: 0.0116 Acc: 99.68%
Epoch: [9/25], Step: [300/468], Loss: 0.0123 Acc: 99.62%
Epoch: [9/25], Step: [400/468], Loss: 0.0127 Acc: 99.60%
Test accuracy: 98.97 % Test loss: 0.0320
Epoch: [10/25], Step: [100/468], Loss: 0.0092 Acc: 99.77%
Epoch: [10/25], Step: [200/468], Loss: 0.0101 Acc: 99.70%
Epoch: [10/25], Step: [300/468], Loss: 0.0120 Acc: 99.65%
Epoch: [10/25], Step: [400/468], Loss: 0.0111 Acc: 99.67%
Test accuracy: 98.90 % Test loss: 0.0318
Epoch: [11/25], Step: [100/468], Loss: 0.0081 Acc: 99.77%
Epoch: [11/25], Step: [200/468], Loss: 0.0089 Acc: 99.75%
Epoch: [11/25], Step: [300/468], Loss: 0.0095 Acc: 99.74%
Epoch: [11/25], Step: [400/468], Loss: 0.0100 Acc: 99.73%
Test accuracy: 99.23 % Test loss: 0.0270
Epoch: [12/25], Step: [100/468], Loss: 0.0069 Acc: 99.77%
Epoch: [12/25], Step: [200/468], Loss: 0.0070 Acc: 99.77%
Epoch: [12/25], Step: [300/468], Loss: 0.0070 Acc: 99.77%
Epoch: [12/25], Step: [400/468], Loss: 0.0078 Acc: 99.75%
Test accuracy: 99.12 % Test loss: 0.0299
Epoch: [13/25], Step: [100/468], Loss: 0.0070 Acc: 99.85%
Epoch: [13/25], Step: [200/468], Loss: 0.0064 Acc: 99.84%
Epoch: [13/25], Step: [300/468], Loss: 0.0072 Acc: 99.81%
Epoch: [13/25], Step: [400/468], Loss: 0.0075 Acc: 99.79%
Test accuracy: 99.20 % Test loss: 0.0301
Epoch: [14/25], Step: [100/468], Loss: 0.0073 Acc: 99.81%
Epoch: [14/25], Step: [200/468], Loss: 0.0080 Acc: 99.78%
Epoch: [14/25], Step: [300/468], Loss: 0.0073 Acc: 99.79%
Epoch: [14/25], Step: [400/468], Loss: 0.0074 Acc: 99.78%
Test accuracy: 99.23 % Test loss: 0.0269
Epoch: [15/25], Step: [100/468], Loss: 0.0083 Acc: 99.70%
Epoch: [15/25], Step: [200/468], Loss: 0.0078 Acc: 99.75%
Epoch: [15/25], Step: [300/468], Loss: 0.0066 Acc: 99.80%
Epoch: [15/25], Step: [400/468], Loss: 0.0066 Acc: 99.81%
Test accuracy: 99.23 % Test loss: 0.0294
Epoch: [16/25], Step: [100/468], Loss: 0.0041 Acc: 99.91%
Epoch: [16/25], Step: [200/468], Loss: 0.0051 Acc: 99.86%
Epoch: [16/25], Step: [300/468], Loss: 0.0047 Acc: 99.88%
Epoch: [16/25], Step: [400/468], Loss: 0.0046 Acc: 99.87%
Test accuracy: 99.14 % Test loss: 0.0303
Epoch: [17/25], Step: [100/468], Loss: 0.0034 Acc: 99.93%
Epoch: [17/25], Step: [200/468], Loss: 0.0042 Acc: 99.91%
Epoch: [17/25], Step: [300/468], Loss: 0.0046 Acc: 99.88%
Epoch: [17/25], Step: [400/468], Loss: 0.0045 Acc: 99.89%
Test accuracy: 99.16 % Test loss: 0.0305
Epoch: [18/25], Step: [100/468], Loss: 0.0025 Acc: 99.94%
Epoch: [18/25], Step: [200/468], Loss: 0.0028 Acc: 99.92%
Epoch: [18/25], Step: [300/468], Loss: 0.0034 Acc: 99.90%
Epoch: [18/25], Step: [400/468], Loss: 0.0031 Acc: 99.91%
Test accuracy: 99.24 % Test loss: 0.0295
Epoch: [19/25], Step: [100/468], Loss: 0.0023 Acc: 99.95%
Epoch: [19/25], Step: [200/468], Loss: 0.0023 Acc: 99.96%
Epoch: [19/25], Step: [300/468], Loss: 0.0023 Acc: 99.96%
Epoch: [19/25], Step: [400/468], Loss: 0.0022 Acc: 99.96%
Test accuracy: 99.21 % Test loss: 0.0306
Epoch: [20/25], Step: [100/468], Loss: 0.0018 Acc: 99.96%
Epoch: [20/25], Step: [200/468], Loss: 0.0015 Acc: 99.97%
Epoch: [20/25], Step: [300/468], Loss: 0.0014 Acc: 99.97%
Epoch: [20/25], Step: [400/468], Loss: 0.0019 Acc: 99.96%
Test accuracy: 99.25 % Test loss: 0.0310
Epoch: [21/25], Step: [100/468], Loss: 0.0008 Acc: 99.98%
Epoch: [21/25], Step: [200/468], Loss: 0.0009 Acc: 99.98%
Epoch: [21/25], Step: [300/468], Loss: 0.0009 Acc: 99.98%
Epoch: [21/25], Step: [400/468], Loss: 0.0012 Acc: 99.97%
Test accuracy: 99.17 % Test loss: 0.0331
Epoch: [22/25], Step: [100/468], Loss: 0.0010 Acc: 99.98%
Epoch: [22/25], Step: [200/468], Loss: 0.0008 Acc: 99.99%
Epoch: [22/25], Step: [300/468], Loss: 0.0009 Acc: 99.98%
Epoch: [22/25], Step: [400/468], Loss: 0.0009 Acc: 99.99%
Test accuracy: 99.29 % Test loss: 0.0314
Epoch: [23/25], Step: [100/468], Loss: 0.0007 Acc: 100.00%
Epoch: [23/25], Step: [200/468], Loss: 0.0007 Acc: 100.00%
Epoch: [23/25], Step: [300/468], Loss: 0.0008 Acc: 99.99%
Epoch: [23/25], Step: [400/468], Loss: 0.0007 Acc: 99.99%
Test accuracy: 99.20 % Test loss: 0.0328
Epoch: [24/25], Step: [100/468], Loss: 0.0013 Acc: 99.96%
Epoch: [24/25], Step: [200/468], Loss: 0.0012 Acc: 99.97%
Epoch: [24/25], Step: [300/468], Loss: 0.0011 Acc: 99.98%
Epoch: [24/25], Step: [400/468], Loss: 0.0010 Acc: 99.98%
Test accuracy: 99.22 % Test loss: 0.0321
Epoch: [25/25], Step: [100/468], Loss: 0.0005 Acc: 99.99%
Epoch: [25/25], Step: [200/468], Loss: 0.0006 Acc: 99.99%
Epoch: [25/25], Step: [300/468], Loss: 0.0006 Acc: 99.99%
Epoch: [25/25], Step: [400/468], Loss: 0.0005 Acc: 99.99%
Test accuracy: 99.14 % Test loss: 0.0341
